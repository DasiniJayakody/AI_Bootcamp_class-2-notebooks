{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854488f2",
   "metadata": {},
   "source": [
    "# üöÄ OpenAI Python SDK 101\n",
    "\n",
    "In this notebook we‚Äôll learn how to interact with Large Language Models (LLMs) directly using the **OpenAI Python SDK**.  \n",
    "This is the **first time** we‚Äôre exploring API interactions, so we‚Äôll build up gradually:\n",
    "\n",
    "1. **Initialize** the client with your API key.  \n",
    "2. **Minimal call** to the API (Responses API).  \n",
    "3. Use **Chat Completions** for system + user roles.  \n",
    "4. Explore **temperature** (randomness) and **top_p** (nucleus sampling).  \n",
    "5. Add **system prompts** to guide behavior.  \n",
    "6. Try **streaming tokens** (like ChatGPT typing).  \n",
    "7. Get **JSON/structured outputs** with schemas.  \n",
    "8. Handle **errors, timeouts, and retries** gracefully.\n",
    "\n",
    "By the end, you‚Äôll know how to **call an LLM safely and flexibly** using just the OpenAI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "844e5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf239a",
   "metadata": {},
   "source": [
    "### API key\n",
    "- Set your OpenAI API key as an environment variable:  \n",
    "  `export OPENAI_API_KEY=\"sk-...\"` (macOS/Linux) or `setx OPENAI_API_KEY \"sk-...\"` (Windows, new terminal required).  \n",
    "- In Colab: use `os.environ[\"OPENAI_API_KEY\"] = \"...\"` (for demos only).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b03c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Python SDK v1 style\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c9cd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature controls the randomness of predictions in sampling, affecting how diverse the outputs are, while top_p (nucleus sampling) limits the choices to a certain cumulative probability, ensuring that only the most likely words are considered for selection.\n"
     ]
    }
   ],
   "source": [
    "# Minimal \"Responses API\" call (recommended by OpenAI for new projects)\n",
    "# Docs: https://platform.openai.com/docs/guides/text  and Responses vs Chat Completions\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",  # choose any available text-capable model\n",
    "    input=\"In one sentence, explain the difference between temperature and top_p for sampling.\"\n",
    ")\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23364e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0c95f9131e39d43b0068f337079c588198b0e1cac18930c271', created_at=1760769799.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_0c95f9131e39d43b0068f3370853608198a3d01b31b018a9e1', content=[ResponseOutputText(annotations=[], text='Temperature controls the randomness of predictions in sampling, affecting how diverse the outputs are, while top_p (nucleus sampling) limits the choices to a certain cumulative probability, ensuring that only the most likely words are considered for selection.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=22, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=46, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=68), user=None, billing={'payer': 'developer'}, store=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff892c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Definition**: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and outliers, which leads to poor performance on unseen data.\n",
      "\n",
      "- **Symptoms**: A model exhibiting overfitting usually shows very low training error but high validation or test error, indicating that it has memorized the training data instead of generalizing from it.\n",
      "\n",
      "- **Prevention Techniques**: Common strategies to prevent overfitting include using cross-validation, simplifying the model (e.g., reducing complexity), employing regularization techniques (like L1 or L2), and using dropout in neural networks.\n"
     ]
    }
   ],
   "source": [
    "# Using Chat Completions (still widely used & supported)\n",
    "chat = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise teaching assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me 3 bullet points about overfitting.\"}\n",
    "    ]\n",
    ")\n",
    "print(chat.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d05319c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CRuwrkBLaqjVVmDqLdPS2FxGZBms9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='- **Definition**: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and outliers, which leads to poor performance on unseen data.\\n\\n- **Symptoms**: A model exhibiting overfitting usually shows very low training error but high validation or test error, indicating that it has memorized the training data instead of generalizing from it.\\n\\n- **Prevention Techniques**: Common strategies to prevent overfitting include using cross-validation, simplifying the model (e.g., reducing complexity), employing regularization techniques (like L1 or L2), and using dropout in neural networks.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760769801, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=124, prompt_tokens=29, total_tokens=153, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5dddecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can reverse a string in Python using slicing. Here's a simple example:\n",
      "\n",
      "```python\n",
      "original_string = \"Hello, World!\"\n",
      "reversed_string = original_string[::-1]\n",
      "print(reversed_string)\n",
      "```\n",
      "\n",
      "Output:\n",
      "```\n",
      "!dlroW ,olleH\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Python tutor who answers with short code examples.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Show how to reverse a string in Python.\"}\n",
    "]\n",
    "r = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, temperature=2) #High temperature for more creative output\n",
    "print(r.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "553e975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once in a quaint little town, there lived a plucky cat named Whiskers and a jovial dog named Buster. Whiskers, with her sleek gray fur and shimmering green eyes, prided herself on her finesse. She spent her days lounging atop a sun-drenched fence, watching the world below with a dispassionate grace. Buster, on the other hand, was a fluffy golden retriever with a heart as big as his bark. He loved nothing more than chasing butterflies and making friends with anyone he met.\n",
      "\n",
      "Despite their differences, Whiskers and Buster shared a common ground‚Äîthe sprawling, vibrant park on the edge of town. Every afternoon, while the sun cast golden rays on the grass, they would meet at their usual spot under the grand old oak tree. Although they often looked at each other with wariness, an unspoken pact had formed between them, and they relished the comfort of each other's presence.\n",
      "\n",
      "One sunny afternoon, an unusual rustle in the bushes caught Whiskers‚Äô keen ear. ‚ÄúDo you hear that, Buster?‚Äù she asked, her voice a mix of curiosity and caution. Buster perked up, his tail wagging in excitement. ‚ÄúLet‚Äôs investigate!‚Äù he urged, bounding toward the shrubbery.\n",
      "\n",
      "With a flick of her tail, Whiskers followed, albeit with more calculated steps. As they reached the bushes, they discovered a tiny, trembling kitten caught in a tangle of leaves. Its big blue eyes gazed up at them, filled with fear.\n",
      "\n",
      "‚ÄúPoor thing,‚Äù whispered Whiskers, instinctively stepping closer. But the poor kitten flinched back, confused and scared. Buster, sensing the tension, softened his demeanor. ‚ÄúHey there, little one,‚Äù he said gently. ‚ÄúWe won‚Äôt hurt you. What‚Äôs your name?‚Äù\n",
      "\n",
      "The kitten hesitated, then whispered, ‚ÄúMittens.‚Äù\n",
      "\n",
      "‚ÄúNice to meet you, Mittens!‚Äù Buster‚Äôs sunny voice filled the air as he lowered himself, making sure he looked less intimidating. ‚ÄúWe‚Äôre here to help!‚Äù\n",
      "\n",
      "Whiskers took a deep breath. She knew that the best way to help was to use her quick thinking. ‚ÄúBuster, can you carefully distract the kitten while I figure out how to set her free?‚Äù With a nod, Buster began wagging his tail more vigorously, pretending to playfully chase his own tail. Mittens watched, momentarily forgetting her fear.\n",
      "\n",
      "While Buster engaged the kitten, Whiskers deftly approached the tangled leaves. With a gentle paw and a careful flick, she began to untangle the kitten‚Äôs fur. Mittens felt her body loosen as the tension faded, and soon, she was free.\n",
      "\n",
      "With a delighted meow, Mittens purred, rubbing against Whiskers‚Äô legs, ‚ÄúThank you! I was so scared!‚Äù\n",
      "\n",
      "Whiskers purred back, surprised by her own warmth. ‚ÄúIt was a team effort.‚Äù\n",
      "\n",
      "Buster jumped up excitedly. ‚ÄúLet‚Äôs play, Mittens! We can chase butterflies together!‚Äù\n",
      "\n",
      "Over the next few weeks, the unlikely trio became inseparable. Whiskers taught Mittens the grace of climbing trees, while Buster showed her the joys of running through the grass and barking at the wind. Their days filled with laughter and adventures, they transformed the park into their playground.\n",
      "\n",
      "One evening, as the sun dipped below the horizon, painting the sky in hues of orange and pink, Whiskers, Buster, and Mittens lay beneath the oak tree, tired but content. Whiskers realized something she had never acknowledged before. Life wasn‚Äôt just about watching from a distance; it was about connection, friendship, and a little bit of adventure.\n",
      "\n",
      "Buster nudged Whiskers and Mittens with his nose. ‚ÄúWhat should we do tomorrow?‚Äù he asked, his eyes bright with enthusiasm.\n",
      "\n",
      "Whiskers smiled, looking at her two dear friends. ‚ÄúAnything we want, as long as we do it together.‚Äù\n",
      "\n",
      "And so, it was the beginning of a beautiful friendship between a cat, a dog, and a kitten, reminding everyone in the little town that love knows no boundaries, and true friendship can come in all shapes and sizes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import stdout\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a short story about a cat and a dog.\"}],\n",
    "    temperature=1,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if hasattr(event, \"choices\"):\n",
    "        delta = event.choices[0].delta\n",
    "        if delta and delta.content:\n",
    "            stdout.write(delta.content)\n",
    "stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6e2b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"item\": \"Rice\", \n",
      "        \"quantity\": 3 \n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Dhal\", \n",
      "        \"quantity\": 4 \n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Biscuits\", \n",
      "        \"quantity\": 3 \n",
      "    },\n",
      "    {\n",
      "        \"item\": \"Sugar\", \n",
      "        \"quantity\": 2 \n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"I have bought 3 kg of Rice, 4 kg of Dhal, 3 packets of Biscuits, 2 kg of Suger, Format this as a list of json objects with each JSON object in the format:\n",
    "{\n",
    "\"item\": \"<item name>\", \n",
    "\"quantity\": <quantity in kg or packets> \n",
    "}\n",
    "\n",
    "DO NOT include anything else in the response\"\"\"\n",
    "\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8fe589e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = completion.choices[0].message.content\n",
    "\n",
    "items = json.loads(response)\n",
    "type(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "843dd69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rice\n",
      "Dhal\n",
      "Biscuits\n",
      "Sugar\n"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    print(item[\"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a7efd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary(topic='Transformers in NLP', key_points=['Transformers utilize self-attention mechanisms to weigh the importance of different words in a sentence, allowing for better context understanding.', 'They enable parallel processing of data, significantly speeding up training times compared to previous sequential models like RNNs and LSTMs.', 'Transformers have led to the development of powerful pre-trained models (e.g., BERT, GPT) that can be fine-tuned for various NLP tasks, achieving state-of-the-art results.'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    topic: str\n",
    "    key_points: List[str]\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    response_format=Summary,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Topic: Transformers in NLP. Give 3 key points.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "parsed = completion.choices[0].message.parsed\n",
    "parsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
